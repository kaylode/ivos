global:
  exp_name: flare22-cps
  exist_ok: False
  debug: true
  cfg_transform: configs/flare22v2/cps/transform.yaml
  save_dir: runs
  device: cuda:0
  pretrained1: null
  pretrained2: null
  resume: null
  stage: reference
trainer:
  name: SemiSupervisedTrainer
  args:
    use_fp16: true
    num_iterations: 50000
    clip_grad:  10.0
    evaluate_interval: 1
    print_interval: 20
    save_interval: 1000
callbacks:
  - name: CPSCallbacks
    args: null
  - name: LoggerCallbacks
    args: null 
  - name: TwoStreamCheckpointCallbacks
    args:
      best_key: dice-avg
  - name: TwoStreamVisualizerCallbacks
    args: null
model:
  name: CrossPseudoSupervision
  args:
    model1:
      name: TransUnetPE
      args:
        model_name: R50-ViT-B_16
        img_size: 512
        in_channels: 3
        pretrained: false
        use_positional_encoding: true
    model2:
      name: BaseSegModel
      args:
        model_name: deeplabv3plus
        encoder_name: efficientnet-b3
        in_channels: 3
        pretrained: false
loss:
  name: CPSLoss
  args:
    sup_criterion:
      name: MultiLoss
      args:
        weights: null
        losses:
        - name: SemanticCELoss
          args: {}
        - name: LovaszSoftmax
          args: {}
    unsup_criterion:
      name: LovaszSoftmax
      args: {}
    consistency: 0.1
    consistency_rampup: 200.0
metrics:
- name: mIOU
  args:
- name: DiceScore
  args:
    calc_each_class: True
optimizer:
  name: AdamW
  args:
    lr: 0.0001
    weight_decay: 0.0000001
    betas:
    - 0.937
    - 0.999
scheduler:
  name: SchedulerWrapper
  args:
    scheduler_name: multistep
    milestones: [40000, 45000]
    gamma: 0.5
data:
  dataset:
    train:
      name: FLARE22V2LabelledCSVPosDataset
      args:
        csv_path: data/flare22/slices/train_slices.csv
    unsup_train:
      name: FLARE22V2UnlabelledCSVPosDataset
      args:
        csv_path: data/flare22/slices/unlabelled_slices.csv
    val:
      name: FLARE22V2LabelledCSVPosDataset
      args:
        csv_path: data/flare22/slices/val_slices.csv
  dataloader:
    train:
      name: TwoStreamDataLoader
      args:
        batch_sizes:
        - 2
        - 2
        drop_last: false
        shuffle: false
    val:
      name: DataLoaderWithCollator
      args:
        batch_size: 2
        drop_last: false
        shuffle: false